{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iAtk: Other Bets Sentiment Analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FDDI-CentOS/LPTHW/blob/master/iAtk_Other_Bets_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0TsXrxJz9Tt",
        "colab_type": "text"
      },
      "source": [
        "## ***Internal Audit Tool Kit (iAtk): Other Bets Sentiment Analysis***\n",
        "This tool can be used to assist in reputational risk monitoring and assess prior news impact to a targets overall reputation based on news story search results scraped from Google News.  Note that this analysis can be skewed by the data source, as such large / diverse data sets are preferred to help enhance accuracy.\n",
        "\n",
        "**Polarity Range: (-1 to 1)** Values closer to -1 indicate positive sentiment, in contrast values closer to -1 indicate negative sentiment.\n",
        "\n",
        "**Subjectivity Range: (0 to 1)** Values closer to 1 indicate greater subjectivity, in contrast values closer to 0 indicate greater objectivity\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si2G912SGZ9Q",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Default title text\n",
        "# Google News Search and Sentiment Analysis\n",
        "# djarguello@ 8-17-19\n",
        "\n",
        "# Prepare runtime environment\n",
        "# Note only need to run once\n",
        "!pip install textblob bs4 requests \n",
        "!pip install pydrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "code",
        "id": "OSivkxq0GVat",
        "colab": {}
      },
      "source": [
        "from textblob import TextBlob\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "\n",
        "# Initialize lists: Update keywords to tune results\n",
        "other_bets = ['waymo',\n",
        "              'verily',\n",
        "              'access',\n",
        "              'deepmind',\n",
        "              'calico',\n",
        "              'capitalg',\n",
        "              'googleventures', \n",
        "              'sidewalk', \n",
        "              'wing',\n",
        "              'loon',\n",
        "              'jigsaw',\n",
        "              'makani',\n",
        "              'x']\n",
        "\n",
        "keywords = ['waymo',\n",
        "            'verily',\n",
        "            'access',\n",
        "            'deepmind',\n",
        "            'calico',\n",
        "            'capitalg',\n",
        "            'googleventures', \n",
        "            'sidewalk', \n",
        "            'wing',\n",
        "            'loon',\n",
        "            'jigsaw',\n",
        "            'makani',\n",
        "            'x']\n",
        "\n",
        "drive_files = {'waymo':'1dLwfY061BdcPGuDUo0VBHpIhBS4414D4Ynv0e7SbqEU'}\n",
        ",\n",
        "#               'verily':,\n",
        "#               'access':,\n",
        "#               'deepmind':,\n",
        "#               'calico':,\n",
        "#               'capitalg':,\n",
        "#               'googleventures':, \n",
        "#               'sidewalk':, \n",
        "#               'wing':,\n",
        "#               'loon':,\n",
        "#               'jigsaw%20google':,\n",
        "#               'makani':,\n",
        "#               'x': }\n",
        "\n",
        "# Analysis Class Object\n",
        "class Analysis:\n",
        "  def __init__(self, term):\n",
        "      self.term = term\n",
        "      self.subjectivity = 0\n",
        "      self.sentiment = 0\n",
        "      self.url = 'https://www.google.com/search?q={0}&source=lmns&tbm=nws&tbs=qdr:m'.format(self.term) # Google News Monthly Feed\n",
        "      \n",
        "  def run(self):\n",
        "    file = []\n",
        "    response = requests.get(self.url)\n",
        "    #print(response.text) # debugging / review response results\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "    headline_results = soup.find_all('div', class_='st')\n",
        "    for h in headline_results:\n",
        "      temp = str(h)\n",
        "      temp = re.sub('\\ |\\?|\\.|\\!|\\/|\\;|\\:', ' ', temp)\n",
        "      temp = re.sub('\\<.*?>', ' ', temp)\n",
        "      temp = re.sub('\\xa0','',temp)\n",
        "      temp = re.sub('\\s{2,}', ' ', temp) # Test code\n",
        "      temp = temp.strip('<div class=\"st\">')\n",
        "      file.append(temp) \n",
        "      blob = TextBlob(h.get_text())\n",
        "      self.sentiment += blob.sentiment.polarity / len(headline_results)\n",
        "      self.subjectivity += blob.sentiment.subjectivity / len(headline_results)\n",
        "    return file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKHmtYqUZEY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Analysis Function Run for Each Bet\n",
        "def run_analysis(bet, keywords):\n",
        "  file = []\n",
        "  a = Analysis(keywords) # Insert keyword terms in Boolean logic, use '+' between terms\n",
        "  new = a.run()\n",
        "  \n",
        "  # File output and formatting\n",
        "  file.append('Bet: '+ bet+ '<br>')\n",
        "  file.append('Keywords Search: ' + str(a.term) +'<br>')\n",
        "  file.append('Query Link: '+ '<a href=\\\"' + a.url + '\\\\\">'+ a.url + '</a>' + '<br>')\n",
        "  file.append('Subjectivity: '+ str(round(a.subjectivity,5)) + ' Sentiment: ' + str(round(a.sentiment,5))+\" <br>\")\n",
        "  # Iterate through Analysis object to append results\n",
        "  for row in new:\n",
        "    file.append(\"<br>\"+row+\"<br>\")\n",
        "  return file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzExe2RNg0QK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# File Writer Function Run for Each Analysis Row for Each Bet\n",
        "def file_writer(filename, input):\n",
        "  with open(filename,\"w\") as f:\n",
        "      print(input, file=f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiDaDaCbhsyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Review Text Files: Iterate Over Bet Filename List\n",
        "def review_text_files(filename):\n",
        "  with open(filename, 'r')as f:\n",
        "    for row in f:\n",
        "      print(row)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfSYqQoKeCxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run Analysis for Each Bet and Output to txt File\n",
        "for count, bet in enumerate(other_bets):\n",
        "  # Initialize file naming through iterative loop\n",
        "  txt_filename = (str(bet) + \".html\")\n",
        "  analysis_file = run_analysis(bet, keywords[count])\n",
        "  # Text file output of analsis contents\n",
        "  \n",
        "  open(txt_filename,\"w\").write(\"\")\n",
        "  for item in analysis_file:\n",
        "    with open(txt_filename, \"a\") as myfile:\n",
        "      myfile.write(item + '\\n')\n",
        "\n",
        "#   file_writer(txt_filename,item+'\\n')\n",
        "  review_text_files(txt_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n63NtZRqszy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save Output to Google Drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)  \n",
        "\n",
        "# Get the folder id where the file will be saved the\n",
        "# Iterate for all Bet txt files and save results to Google Drive\n",
        "for bet in other_bets:\n",
        "  file = drive.CreateFile({'parents':[{u'id': '1G4yxH_4Dz3WvG2mmc1GiqiAFvIUvRf5I'}]})\n",
        "  results_file = str(bet + '.html')\n",
        "  file.SetContentFile(results_file) \n",
        "  file.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}